{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Solving Inverse Problems with Spectral Dynamic Causal Modeling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "Neuroblox provides you with a comprehensive environment for simulations as we have explored previously, but its functionality doesn't stop there.\n",
    "We will now pivot and turn our attention to a different kind of problem:\n",
    "inferring model parameters, that is solving inverse problems, from time series.\n",
    "The method of choice is one of the most widely spread in imaging neuroscience, spectral Dynamic Causal Modeling (spDCM)[1,2].\n",
    "In this tutorial we will introduce how to perform a spDCM analysis on simulated data.\n",
    "To do so we roughly reproduce the procedure in the [SPM](https://www.fil.ion.ucl.ac.uk/spm/software/spm12/) script `DEM_demo_induced_fMRI.m` in [Neuroblox](https://www.neuroblox.org/).\n",
    "This work was also presented in Hofmann et al.[2]\n",
    "\n",
    "In this session we will define a circuit of three linear neuronal mass models, all driven by an Ornstein-Uhlenbeck process.\n",
    "We will model fMRI data by a balloon model and BOLD signal on top.\n",
    "After simulation of this simple model we will use spDCM to infer some of the model parameters from the simulation time series."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![spDCM Workflow](./assets/spectral_DCM_illustration.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Figure 1: Workflow for Spectral DCM analysis.*\n",
    "\n",
    "*Figure 1* describes the procedure we will pursue:\n",
    "- define the graph and add blocks (sections A, B and C in the Figure)\n",
    "- simulate the model, instead we could also use actual data (section D in Figure)\n",
    "- compute the cross spectral density\n",
    "- setup the DCM\n",
    "- estimate parameters\n",
    "- plot the results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Learning goals\n",
    "- perform the entire workflow of an spDCM analysis.\n",
    "- use observer Blox to simulate experimental measurements."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Neuroblox\n",
    "using LinearAlgebra\n",
    "using StochasticDiffEq\n",
    "using DataFrames\n",
    "using OrderedCollections\n",
    "using CairoMakie\n",
    "using ModelingToolkit\n",
    "using Random"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the model\n",
    "We will define a model of 3 regions. This means first of all to define a graph.\n",
    "To this graph we will add three linear neuronal mass models which constitute the (hidden) neuronal dynamics.\n",
    "These constitute three nodes of the graph.\n",
    "Next we will also need some input that stimulates the activity, we use simple Ornstein-Uhlenbeck blocks to create stochastic inputs.\n",
    "One per region.\n",
    "We want to simulate fMRI signals thus we will need to also add a BalloonModel per region.\n",
    "Note that the Ornstein-Uhlenbeck block will feed into the linear neural mass which in turn will feed into the BalloonModel blox.\n",
    "This needs to be represented by the way we define the edges."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Random.seed!(17)   # set seed for reproducibility\n",
    "\n",
    "nr = 3             # number of regions\n",
    "g = MetaDiGraph()\n",
    "regions = [];      # list of neural mass blocks to then connect them to each other with an adjacency matrix `A_true`"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now add the different blocks to each region and connect the blocks within each region.\n",
    "For convenience we use a for loop since the type of blocks belonging to a each region repeat over regions but you could also approach building the system the same way as was shown in previous tutorials:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "for i = 1:nr\n",
    "    region = LinearNeuralMass(;name=Symbol(\"r$(i)₊lm\"))\n",
    "    push!(regions, region)          # store neural mass model in list. We need this list below. If you haven't seen the Julia command `push!` before [see here](http://jlhub.com/julia/manual/en/function/push-exclamation).\n",
    "\n",
    "    input = OUBlox(;name=Symbol(\"r$(i)₊ou\"), σ=0.1) ## add Ornstein-Uhlenbeck as noisy input to the current region\n",
    "    add_edge!(g, input => region, weight=1/16)\n",
    "\n",
    "    measurement = BalloonModel(;name=Symbol(\"r$(i)₊bm\")) ## simulate fMRI signal with BalloonModel which includes the BOLD signal on top of the balloon model dynamics\n",
    "    add_edge!(g, region => measurement, weight=1.0)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that `weight=1/16` in the connection between the OU process and the Neural Mass Blox is taken from SPM12. This stabilizes the balloon model simulation. Alternatively the noise of the Ornstein-Uhlenbeck block or the weight of the edge connecting neuronal activity and balloon model could be reduced to guarantee numerical stability.\n",
    "Next we define the between-region connectivity matrix and connect regions; we use the same matrix as is defined in [3]"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A_true = [[-0.5 -2 0]; [0.4 -0.5 -0.3]; [0 0.2 -0.5]]\n",
    "for idx in CartesianIndices(A_true)\n",
    "    add_edge!(g, regions[idx[1]] => regions[idx[2]], weight=A_true[idx[1], idx[2]])\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "finally we compose the simulation model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@named simmodel = system_from_graph(g);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the simulation and plot the results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "setup simulation of the model, time in seconds"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tspan = (0.0, 512.0)\n",
    "prob = SDEProblem(simmodel, [], tspan)\n",
    "dt = 2   # 2 seconds (units are seconds) as measurement interval for fMRI\n",
    "sol = solve(prob, ImplicitRKMil(), saveat=dt);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "we now want to extract all the variables in our model which carry the tag \"measurement\". For this purpose we can use the Neuroblox function `get_idx_tagged_vars`\n",
    "the observable quantity in our model is the BOLD signal, the variable of the Blox `BalloonModel` that represents the BOLD signal is tagged with \"measurement\" tag.\n",
    "other tags that are defined are \"input\" which denotes variables representing a stimulus, like for instance an `OUBlox`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "idx_m = get_idx_tagged_vars(simmodel, \"measurement\")    # get index of bold signal"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "plot bold signal time series"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f = Figure()\n",
    "ax = Axis(f[1, 1],\n",
    "    title = \"fMRI time series\",\n",
    "    xlabel = \"Time [ms]\",\n",
    "    ylabel = \"BOLD\",\n",
    ")\n",
    "lines!(ax, sol, idxs=idx_m)\n",
    "f"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We note that the initial spike is not meaningful and a result of the equilibration of the stochastic process thus we remove it."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dfsol = DataFrame(sol[ceil(Int, 101/dt):end]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Estimate and plot the cross-spectral densities"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "data = Matrix(dfsol[:, idx_m]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We compute the cross-spectral density by fitting a linear model of order `p` and then compute the csd analytically from the parameters of the multivariate autoregressive model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p = 8\n",
    "mar = mar_ml(data, p)   # maximum likelihood estimation of the MAR coefficients and noise covariance matrix\n",
    "ns = size(data, 1)\n",
    "freq = range(min(128, ns*dt)^-1, max(8, 2*dt)^-1, 32)\n",
    "csd = mar2csd(mar, freq, dt^-1);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now plot the cross-spectrum:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fig = Figure(size=(1200, 800))\n",
    "grid = fig[1, 1] = GridLayout()\n",
    "for i = 1:nr\n",
    "    for j = 1:nr\n",
    "        ax = Axis(grid[i, j])\n",
    "        lines!(ax, freq, real.(csd[:, i, j]))\n",
    "    end\n",
    "end\n",
    "fig"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will now assemble a new model that is used for fitting the previous simulations.\n",
    "This procedure is similar to before with the difference that we will define global parameters and use tags such as [tunable=false/true] to define which parameters we will want to estimate.\n",
    "Note that parameters are tunable by default."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "g = MetaDiGraph()\n",
    "regions = [];   # list of neural mass blocks to then connect them to each other with an adjacency matrix `A`"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that parameters are typically defined within a Blox and thus not immediately visible to the user.\n",
    "Since we want some parameters to be shared across several regions we define them outside of the regions.\n",
    "For this purpose use the ModelingToolkit macro `@parameters` which is used to define symbolic parameters for models.\n",
    "Note that we can set the tunable flag right away thereby defining whether we will include this parameter in the optimization procedure or rather keep it fixed to its predefined value."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@parameters lnκ=0.0 [tunable=false] lnϵ=0.0 [tunable=false] lnτ=0.0 [tunable=false];   # lnκ: decay parameter for hemodynamics; lnϵ: ratio of intra- to extra-vascular components, lnτ: transit time scale\n",
    "@parameters C=1/16 [tunable=false];   # note that C=1/16 is taken from SPM12 and stabilizes the balloon model simulation. See also comment above."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now define a similar model as above for the simulation but instead of using an actual stimulus Blox we here add ExternalInput which represents a simple linear external input that is not specified any further.\n",
    "We simply say that our model gets some input with a proportional factor $C$. This is mostly only to make sure that our results are consistent with those produced by SPM"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "for i = 1:nr\n",
    "    region = LinearNeuralMass(;name=Symbol(\"r$(i)₊lm\"))\n",
    "    push!(regions, region)\n",
    "    input = ExternalInput(;name=Symbol(\"r$(i)₊ei\"))\n",
    "    add_edge!(g, input => region, weight=C)\n",
    "\n",
    "    measurement = BalloonModel(;name=Symbol(\"r$(i)₊bm\"), lnτ=lnτ, lnκ=lnκ, lnϵ=lnϵ) ## assume fMRI signal and model them with a BalloonModel\n",
    "    add_edge!(g, region => measurement, weight=1.0)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we define the prior expectation values of the effective connectivity matrix we wish to infer:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A_prior = 0.01*randn(nr, nr)\n",
    "A_prior -= diagm(diag(A_prior))    # remove the diagonal"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we want to optimize these weights we turn them into symbolic parameters:\n",
    "Add the symbolic weights to the edges and connect regions."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A = []\n",
    "for (i, a) in enumerate(vec(A_prior))\n",
    "    symb = Symbol(\"A$(i)\")\n",
    "    push!(A, only(@parameters $symb = a))\n",
    "end\n",
    "\n",
    "for (i, idx) in enumerate(CartesianIndices(A_prior))\n",
    "    if idx[1] == idx[2]\n",
    "        add_edge!(g, regions[idx[1]] => regions[idx[2]], weight=-exp(A[i])/2)  ## -exp(A[i])/2: treatement of diagonal elements in SPM12 to make diagonal dominance (see Gershgorin Theorem) more likely but it is not guaranteed\n",
    "    else\n",
    "        add_edge!(g, regions[idx[2]] => regions[idx[1]], weight=A[i])\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Avoid simplification of the model in order to be able to exclude some parameters from fitting"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@named fitmodel = system_from_graph(g, simplify=false);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the Neuroblox function `changetune` we can provide a dictionary of parameters whose tunable flag should be changed, for instance set to false to exclude them from the optimization procedure.\n",
    "Assume we want to exclude the connections that were set to zero in the simulation:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "untune = Dict(A[3] => false, A[7] => false)\n",
    "fitmodel = changetune(fitmodel, untune)                 # A[3] and A[7] were set to 0 in the simulation\n",
    "fitmodel = structural_simplify(fitmodel, split=false)   # and now simplify the euqations; the `split` parameter is necessary for some ModelingToolkit peculiarities and will soon be removed. So don't lose time with it ;)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup spectral DCM"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "max_iter = 128; # maximum number of iterations"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "attribute initial conditions or default values to dynamic states of our model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sts, _ = get_dynamic_states(fitmodel);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "the following step is needed if the model's Jacobian would give degenerate eigenvalues when expanded around the fixed point 0 (which is the default expansion). We simply add small random values to avoid this degeneracy:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "perturbedfp = Dict(sts .=> abs.(0.001*rand(length(sts))))     # slight noise to avoid issues with Automatic Differentiation."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For convenience we can use the default prior function to use standardized prior values as given in SPM:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pmean, pcovariance, indices = defaultprior(fitmodel, nr)\n",
    "\n",
    "priors = (μθ_pr = pmean,\n",
    "          Σθ_pr = pcovariance\n",
    "         );"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup hyper parameter prior as well:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "hyperpriors = Dict(:Πλ_pr => 128.0*ones(1, 1),   # prior metaparameter precision, needs to be a matrix\n",
    "                   :μλ_pr => [8.0]               # prior metaparameter mean, needs to be a vector\n",
    "                  );"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To compute the cross spectral densities we need to provide the sampling interval of the time series, the frequency axis and the order of the multivariate autoregressive model:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "csdsetup = (mar_order = p, freq = freq, dt = dt);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "earlier we used the function `get_idx_tagged_vars` to get the indices of tagged variables. Here we don't want to get the indices but rather the symbolic variable names themselves in order to get the correct columns of the dataframe of the simulation that correspond to the BOLD signal or measurement:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "_, s_bold = get_eqidx_tagged_vars(fitmodel, \"measurement\");    # get bold signal variables"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepare the DCM. This function will setup the computation of the Dynamic Causal Model. The last parameter specifies that we are using fMRI time series (as opposed to LFPs, which is the other modality that is currently available in Neuroblox)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "(state, setup) = setup_sDCM(dfsol[:, String.(Symbol.(s_bold))], fitmodel, perturbedfp, csdsetup, priors, hyperpriors, indices, pmean, \"fMRI\");"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are now ready to run the optimization procedure!\n",
    "That is we loop over run_sDCM_iteration! which will alter `state` after each optimization iteration. It essentially computes the Variational Laplace estimation of expectation and variance of the tunable parameters."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "for iter in 1:max_iter\n",
    "    state.iter = iter\n",
    "    run_sDCM_iteration!(state, setup)\n",
    "    print(\"iteration: \", iter, \" - F:\", state.F[end], \" - dF predicted:\", state.dF[end], \"\\n\")\n",
    "    if iter >= 4\n",
    "        criterion = state.dF[end-3:end] .< setup.tolerance\n",
    "        if all(criterion)\n",
    "            print(\"convergence\\n\")\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the output `F` is the free energy at each iteration step and `dF` is the predicted change of free energy at each step which approximates the actual free energy change and is used as stopping criterion by requiring that it does not excede the `tolerance` level for 4 consecutive times."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "Free energy is the objective function of the optimization scheme of spectral DCM. Note that in the machine learning literature this it is called Evidence Lower Bound (ELBO).\n",
    "Plot the free energy evolution over optimization iterations to see how the algorithm converges towards a (potentially local) optimum:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f1 = freeenergy(state)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the estimated posterior of the effective connectivity and compare that to the true parameter values.\n",
    "Bar height are the posterior mean and error bars are the standard deviation of the posterior."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f2 = ecbarplot(state, setup, A_true)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Challenge Problems\n",
    "- **Explore susceptibility with respect to noise.** Run the script again with a different random seed and observe how the results change. Given that we didn’t change any parameters of the ground truth, what is your take on parameter inference with this setup? How reliable is model selection based on free energy (compare the different free energies of the models and their respective parameter values with ground truth)?\n",
    "- **Averaging over patients.** Now repeat the simulation and inference again with 10 different seeds (you can just remove the number in Random.seed() to use current time stamps as seeds) and store the results of each run, such that you get several models based on the same ground truth but with different instances of the noise. Can you extract the average value of the effective connectivity from the ensemble?\n",
    "- Changing neuronal dynamics model. Now change the model and test the whole procedure with a different underlying neuronal mass model, for instance the Jansen-Rit model. Note that there are no default priors for the Jansen-Rit model, you will have to provide priors for the extra parameters or remove them from the optimization procedure by setting their tunable to false."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "- [1] [Novelli, Leonardo, Karl Friston, and Adeel Razi. “Spectral Dynamic Causal Modeling: A Didactic Introduction and Its Relationship with Functional Connectivity.” Network Neuroscience 8, no. 1 (April 1, 2024): 178–202.](https://doi.org/10.1162/netn_a_00348) \\\n",
    "- [2] [Hofmann, David, Anthony G. Chesebro, Chris Rackauckas, Lilianne R. Mujica-Parodi, Karl J. Friston, Alan Edelman, and Helmut H. Strey. “Leveraging Julia’s Automated Differentiation and Symbolic Computation to Increase Spectral DCM Flexibility and Speed.” bioRxiv: The Preprint Server for Biology, 2023.](https://doi.org/10.1101/2023.10.27.564407) \\\n",
    "- [3] [Friston, Karl J., Joshua Kahan, Bharat Biswal, and Adeel Razi. “A DCM for Resting State fMRI.” NeuroImage 94 (July 2014): 396–407.](https://linkinghub.elsevier.com/retrieve/pii/S1053811913012135)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}
